{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model as plot\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './lib/')\n",
    "from help_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from extract_patches import get_data_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unet(n_ch,patch_height,patch_width):\n",
    "    inputs = Input(shape=(n_ch,patch_height,patch_width))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(inputs)\n",
    "    conv1 = Dropout(0.2)(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    #\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(pool1)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    #\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_first')(pool2)\n",
    "    conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv3)\n",
    "\n",
    "    up1 = UpSampling2D(size=(2, 2))(conv3)\n",
    "    up1 = concatenate([conv2,up1],axis=1)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(up1)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv4)\n",
    "    #\n",
    "    up2 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    up2 = concatenate([conv1,up2], axis=1)\n",
    "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(up2)\n",
    "    conv5 = Dropout(0.2)(conv5)\n",
    "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_first')(conv5)\n",
    "    #\n",
    "    conv6 = Conv2D(2, (1, 1), activation='relu',padding='same',data_format='channels_first')(conv5)\n",
    "    conv6 = core.Reshape((2,patch_height*patch_width))(conv6)\n",
    "    conv6 = core.Permute((2,1))(conv6)\n",
    "    ############\n",
    "    conv7 = core.Activation('softmax')(conv6)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv7)\n",
    "\n",
    "    # sgd = SGD(lr=0.01, decay=1e-6, momentum=0.3, nesterov=False)\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "#Define the neural network gnet\n",
    "#you need change function call \"get_unet\" to \"get_gnet\" in line 166 before use this network\n",
    "def get_gnet(n_ch,patch_height,patch_width):\n",
    "    inputs = Input((n_ch, patch_height, patch_width))\n",
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(inputs)\n",
    "    conv1 = Dropout(0.2)(conv1)\n",
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv1)\n",
    "    up1 = UpSampling2D(size=(2, 2))(conv1)\n",
    "    #\n",
    "    conv2 = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(up1)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(conv2)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    #\n",
    "    conv3 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(pool1)\n",
    "    conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv3)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    #\n",
    "    conv4 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(pool2)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv4)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    #\n",
    "    conv5 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(pool3)\n",
    "    conv5 = Dropout(0.2)(conv5)\n",
    "    conv5 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv5)\n",
    "    #\n",
    "    up2 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=1)\n",
    "    conv6 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(up2)\n",
    "    conv6 = Dropout(0.2)(conv6)\n",
    "    conv6 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv6)\n",
    "    #\n",
    "    up3 = merge([UpSampling2D(size=(2, 2))(conv6), conv3], mode='concat', concat_axis=1)\n",
    "    conv7 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(up3)\n",
    "    conv7 = Dropout(0.2)(conv7)\n",
    "    conv7 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv7)\n",
    "    #\n",
    "    up4 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=1)\n",
    "    conv8 = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(up4)\n",
    "    conv8 = Dropout(0.2)(conv8)\n",
    "    conv8 = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(conv8)\n",
    "    #\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv8)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(pool4)\n",
    "    conv9 = Dropout(0.2)(conv9)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv9)\n",
    "    #\n",
    "    conv10 = Convolution2D(2, 1, 1, activation='relu', border_mode='same')(conv9)\n",
    "    conv10 = core.Reshape((2,patch_height*patch_width))(conv10)\n",
    "    conv10 = core.Permute((2,1))(conv10)\n",
    "    ############\n",
    "    conv10 = core.Activation('softmax')(conv10)\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "\n",
    "    # sgd = SGD(lr=0.01, decay=1e-6, momentum=0.3, nesterov=False)\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_epochs = 100\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "def write_hdf5(arr,outfile):\n",
    "  with h5py.File(outfile,\"w\") as f:\n",
    "    f.create_dataset(\"image\", data=arr, dtype=arr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train\n",
    "original_imgs_train = \"./DRIVE/training/images/\"\n",
    "groundTruth_imgs_train = \"./DRIVE/training/1st_manual/\"\n",
    "borderMasks_imgs_train = \"./DRIVE/training/mask/\"\n",
    "#test\n",
    "original_imgs_test = \"./DRIVE/test/images/\"\n",
    "groundTruth_imgs_test = \"./DRIVE/test/1st_manual/\"\n",
    "borderMasks_imgs_test = \"./DRIVE/test/mask/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nimgs = 20\n",
    "channels = 3\n",
    "height = 584\n",
    "width = 565\n",
    "dataset_path = \"./DRIVE_datasets_training_testing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_datasets(imgs_dir,groundTruth_dir,borderMasks_dir,train_test=\"null\"):\n",
    "    imgs = np.empty((Nimgs,height,width,channels))\n",
    "    groundTruth = np.empty((Nimgs,height,width))\n",
    "    border_masks = np.empty((Nimgs,height,width))\n",
    "    for path, subdirs, files in os.walk(imgs_dir): #list all files, directories in the path\n",
    "        for i in range(len(files)):\n",
    "            #original\n",
    "            print (\"original image: \" +files[i])\n",
    "            img = Image.open(imgs_dir+files[i])\n",
    "            imgs[i] = np.asarray(img)\n",
    "            #corresponding ground truth\n",
    "            groundTruth_name = files[i][0:2] + \"_manual1.gif\"\n",
    "            print (\"ground truth name: \" + groundTruth_name)\n",
    "            g_truth = Image.open(groundTruth_dir + groundTruth_name)\n",
    "            groundTruth[i] = np.asarray(g_truth)\n",
    "            #corresponding border masks\n",
    "            border_masks_name = \"\"\n",
    "            if train_test==\"train\":\n",
    "                border_masks_name = files[i][0:2] + \"_training_mask.gif\"\n",
    "            elif train_test==\"test\":\n",
    "                border_masks_name = files[i][0:2] + \"_test_mask.gif\"\n",
    "            else:\n",
    "                print (\"specify if train or test!!\")\n",
    "                exit()\n",
    "            print (\"border masks name: \" + border_masks_name)\n",
    "            b_mask = Image.open(borderMasks_dir + border_masks_name)\n",
    "            border_masks[i] = np.asarray(b_mask)\n",
    "    print (\"imgs max: \" +str(np.max(imgs)))\n",
    "    print (\"imgs min: \" +str(np.min(imgs)))\n",
    "    assert(np.max(groundTruth)==255 and np.max(border_masks)==255)\n",
    "    assert(np.min(groundTruth)==0 and np.min(border_masks)==0)\n",
    "    print (\"ground truth and border masks are correctly withih pixel value range 0-255 (black-white)\")\n",
    "    #reshaping for my standard tensors\n",
    "    imgs = np.transpose(imgs,(0,3,1,2))\n",
    "    assert(imgs.shape == (Nimgs,channels,height,width))\n",
    "    groundTruth = np.reshape(groundTruth,(Nimgs,1,height,width))\n",
    "    border_masks = np.reshape(border_masks,(Nimgs,1,height,width))\n",
    "    assert(groundTruth.shape == (Nimgs,1,height,width))\n",
    "    assert(border_masks.shape == (Nimgs,1,height,width))\n",
    "    return imgs, groundTruth, border_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image: 21_training.tif\n",
      "ground truth name: 21_manual1.gif\n",
      "border masks name: 21_training_mask.gif\n",
      "original image: 22_training.tif\n",
      "ground truth name: 22_manual1.gif\n",
      "border masks name: 22_training_mask.gif\n",
      "original image: 23_training.tif\n",
      "ground truth name: 23_manual1.gif\n",
      "border masks name: 23_training_mask.gif\n",
      "original image: 24_training.tif\n",
      "ground truth name: 24_manual1.gif\n",
      "border masks name: 24_training_mask.gif\n",
      "original image: 25_training.tif\n",
      "ground truth name: 25_manual1.gif\n",
      "border masks name: 25_training_mask.gif\n",
      "original image: 26_training.tif\n",
      "ground truth name: 26_manual1.gif\n",
      "border masks name: 26_training_mask.gif\n",
      "original image: 27_training.tif\n",
      "ground truth name: 27_manual1.gif\n",
      "border masks name: 27_training_mask.gif\n",
      "original image: 28_training.tif\n",
      "ground truth name: 28_manual1.gif\n",
      "border masks name: 28_training_mask.gif\n",
      "original image: 29_training.tif\n",
      "ground truth name: 29_manual1.gif\n",
      "border masks name: 29_training_mask.gif\n",
      "original image: 30_training.tif\n",
      "ground truth name: 30_manual1.gif\n",
      "border masks name: 30_training_mask.gif\n",
      "original image: 31_training.tif\n",
      "ground truth name: 31_manual1.gif\n",
      "border masks name: 31_training_mask.gif\n",
      "original image: 32_training.tif\n",
      "ground truth name: 32_manual1.gif\n",
      "border masks name: 32_training_mask.gif\n",
      "original image: 33_training.tif\n",
      "ground truth name: 33_manual1.gif\n",
      "border masks name: 33_training_mask.gif\n",
      "original image: 34_training.tif\n",
      "ground truth name: 34_manual1.gif\n",
      "border masks name: 34_training_mask.gif\n",
      "original image: 35_training.tif\n",
      "ground truth name: 35_manual1.gif\n",
      "border masks name: 35_training_mask.gif\n",
      "original image: 36_training.tif\n",
      "ground truth name: 36_manual1.gif\n",
      "border masks name: 36_training_mask.gif\n",
      "original image: 37_training.tif\n",
      "ground truth name: 37_manual1.gif\n",
      "border masks name: 37_training_mask.gif\n",
      "original image: 38_training.tif\n",
      "ground truth name: 38_manual1.gif\n",
      "border masks name: 38_training_mask.gif\n",
      "original image: 39_training.tif\n",
      "ground truth name: 39_manual1.gif\n",
      "border masks name: 39_training_mask.gif\n",
      "original image: 40_training.tif\n",
      "ground truth name: 40_manual1.gif\n",
      "border masks name: 40_training_mask.gif\n",
      "imgs max: 255.0\n",
      "imgs min: 0.0\n",
      "ground truth and border masks are correctly withih pixel value range 0-255 (black-white)\n",
      "saving train datasets\n",
      "original image: 01_test.tif\n",
      "ground truth name: 01_manual1.gif\n",
      "border masks name: 01_test_mask.gif\n",
      "original image: 02_test.tif\n",
      "ground truth name: 02_manual1.gif\n",
      "border masks name: 02_test_mask.gif\n",
      "original image: 03_test.tif\n",
      "ground truth name: 03_manual1.gif\n",
      "border masks name: 03_test_mask.gif\n",
      "original image: 04_test.tif\n",
      "ground truth name: 04_manual1.gif\n",
      "border masks name: 04_test_mask.gif\n",
      "original image: 05_test.tif\n",
      "ground truth name: 05_manual1.gif\n",
      "border masks name: 05_test_mask.gif\n",
      "original image: 06_test.tif\n",
      "ground truth name: 06_manual1.gif\n",
      "border masks name: 06_test_mask.gif\n",
      "original image: 07_test.tif\n",
      "ground truth name: 07_manual1.gif\n",
      "border masks name: 07_test_mask.gif\n",
      "original image: 08_test.tif\n",
      "ground truth name: 08_manual1.gif\n",
      "border masks name: 08_test_mask.gif\n",
      "original image: 09_test.tif\n",
      "ground truth name: 09_manual1.gif\n",
      "border masks name: 09_test_mask.gif\n",
      "original image: 10_test.tif\n",
      "ground truth name: 10_manual1.gif\n",
      "border masks name: 10_test_mask.gif\n",
      "original image: 11_test.tif\n",
      "ground truth name: 11_manual1.gif\n",
      "border masks name: 11_test_mask.gif\n",
      "original image: 12_test.tif\n",
      "ground truth name: 12_manual1.gif\n",
      "border masks name: 12_test_mask.gif\n",
      "original image: 13_test.tif\n",
      "ground truth name: 13_manual1.gif\n",
      "border masks name: 13_test_mask.gif\n",
      "original image: 14_test.tif\n",
      "ground truth name: 14_manual1.gif\n",
      "border masks name: 14_test_mask.gif\n",
      "original image: 15_test.tif\n",
      "ground truth name: 15_manual1.gif\n",
      "border masks name: 15_test_mask.gif\n",
      "original image: 16_test.tif\n",
      "ground truth name: 16_manual1.gif\n",
      "border masks name: 16_test_mask.gif\n",
      "original image: 17_test.tif\n",
      "ground truth name: 17_manual1.gif\n",
      "border masks name: 17_test_mask.gif\n",
      "original image: 18_test.tif\n",
      "ground truth name: 18_manual1.gif\n",
      "border masks name: 18_test_mask.gif\n",
      "original image: 19_test.tif\n",
      "ground truth name: 19_manual1.gif\n",
      "border masks name: 19_test_mask.gif\n",
      "original image: 20_test.tif\n",
      "ground truth name: 20_manual1.gif\n",
      "border masks name: 20_test_mask.gif\n",
      "imgs max: 255.0\n",
      "imgs min: 0.0\n",
      "ground truth and border masks are correctly withih pixel value range 0-255 (black-white)\n",
      "saving test datasets\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "#getting the training datasets\n",
    "imgs_train, groundTruth_train, border_masks_train = get_datasets(original_imgs_train,groundTruth_imgs_train,borderMasks_imgs_train,\"train\")\n",
    "print (\"saving train datasets\")\n",
    "write_hdf5(imgs_train, dataset_path + \"DRIVE_dataset_imgs_train.hdf5\")\n",
    "write_hdf5(groundTruth_train, dataset_path + \"DRIVE_dataset_groundTruth_train.hdf5\")\n",
    "write_hdf5(border_masks_train,dataset_path + \"DRIVE_dataset_borderMasks_train.hdf5\")\n",
    "\n",
    "#getting the testing datasets\n",
    "imgs_test, groundTruth_test, border_masks_test = get_datasets(original_imgs_test,groundTruth_imgs_test,borderMasks_imgs_test,\"test\")\n",
    "print (\"saving test datasets\")\n",
    "write_hdf5(imgs_test,dataset_path + \"DRIVE_dataset_imgs_test.hdf5\")\n",
    "write_hdf5(groundTruth_test, dataset_path + \"DRIVE_dataset_groundTruth_test.hdf5\")\n",
    "write_hdf5(border_masks_test,dataset_path + \"DRIVE_dataset_borderMasks_test.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train images/masks shape:\n",
      "(20, 1, 565, 565)\n",
      "train images range (min-max): 0.0 - 1.0\n",
      "train masks are within 0-1\n",
      "\n",
      "patches per full image: 9500\n",
      "\n",
      "train PATCHES images/masks shape:\n",
      "(190000, 1, 48, 48)\n",
      "train PATCHES images range (min-max): 0.0 - 1.0\n"
     ]
    }
   ],
   "source": [
    "patches_imgs_train, patches_masks_train = get_data_training(\n",
    "    DRIVE_train_imgs_original = 'DRIVE_datasets_training_testing/DRIVE_dataset_imgs_train.hdf5',\n",
    "    DRIVE_train_groudTruth = 'DRIVE_datasets_training_testing/DRIVE_dataset_borderMasks_train.hdf5',  #masks\n",
    "    patch_height = 48,\n",
    "    patch_width = 48,\n",
    "    N_subimgs = 190000,\n",
    "    inside_FOV = False #select the patches only inside the FOV  (default == True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_ch = patches_imgs_train.shape[1]\n",
    "patch_height = patches_imgs_train.shape[2]\n",
    "patch_width = patches_imgs_train.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Akshayaa\\Anacond3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1213: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Akshayaa\\Anacond3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1247: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Akshayaa\\Anacond3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model = get_unet(n_ch, patch_height, patch_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2304, 2)\n"
     ]
    }
   ],
   "source": [
    "print (model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patches_masks_train = masks_Unet(patches_masks_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(patches_imgs_train, patches_masks_train, nb_epoch=N_epochs, batch_size=batch_size, verbose=2, shuffle=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a6071114a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(patches_imgs_train[0][0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
